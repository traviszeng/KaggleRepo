{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from bayes_opt import BayesianOptimization\n",
    "import lightgbm as lgb\n",
    "import os, sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Load data \n",
    "train = pd.read_csv('../input/bigquery-geotab-intersection-congestion/train.csv')\n",
    "test = pd.read_csv('../input/bigquery-geotab-intersection-congestion/test.csv')\n",
    "submission = pd.read_csv('../input/bigquery-geotab-intersection-congestion/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:blue;background:yellow'>Data Cleaning and Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train[\"City\"].unique())\n",
    "print(test[\"City\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.groupby([\"City\"]).apply(np.unique)\n",
    "test.groupby([\"City\"]).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style='color:blue;background:yellow'>**Fill NAs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# def fill_na(df):\n",
    "#     df['ExitStreetName'] = df.apply(lambda x: x.EntryStreetName if type(x.ExitStreetName) != str else x.ExitStreetName, axis =1)\n",
    "#     df['EntryStreetName'] = df.apply(lambda x: x.ExitStreetName if type(x.EntryStreetName) != str else x.EntryStreetName, axis =1)\n",
    "#     df.fillna('ffill', inplace=True)\n",
    "#     return df\n",
    "# train = fill_na(train)\n",
    "# test = fill_na(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue;background:yellow'> Road Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_encoding = {\n",
    "\"Street\":0,\n",
    " \"St\":0,\n",
    " \"Avenue\":1,\n",
    " \"Ave\":1,\n",
    " \"Boulevard\":2,\n",
    " \"Road\":3,\n",
    " \"Drive\":4,\n",
    " \"Lane\":5,\n",
    " \"Tunnel\":6,\n",
    " \"Highway\":7,\n",
    " \"Way\":8,\n",
    " \"Parkway\":9,\n",
    " \"Parking\":10,\n",
    " \"Oval\":11,\n",
    " \"Square\":12,\n",
    " \"Place\":13,\n",
    " \"Bridge\":14}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(x):\n",
    "    if pd.isna(x):\n",
    "        return 0\n",
    "    for road in road_encoding.keys():\n",
    "        if road in x:\n",
    "            return road_encoding[road]\n",
    "        \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['EntryType'] = train['EntryStreetName'].apply(encode)\n",
    "train['ExitType'] = train['ExitStreetName'].apply(encode)\n",
    "test['EntryType'] = test['EntryStreetName'].apply(encode)\n",
    "test['ExitType'] = test['ExitStreetName'].apply(encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue;background:yellow'> add cordinal direction\n",
    "##### turn direction: \n",
    "The cardinal directions can be expressed using the equation: $$ \\frac{\\theta}{\\pi} $$\n",
    "\n",
    "Where $\\theta$ is the angle between the direction we want to encode and the north compass direction, measured clockwise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directions = {\n",
    "    'N': 0,\n",
    "    'NE': 1/4,\n",
    "    'E': 1/2,\n",
    "    'SE': 3/4,\n",
    "    'S': 1,\n",
    "    'SW': 5/4,\n",
    "    'W': 3/2,\n",
    "    'NW': 7/4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['EntryHeading'] = train['EntryHeading'].map(directions)\n",
    "train['ExitHeading'] = train['ExitHeading'].map(directions)\n",
    "\n",
    "test['EntryHeading'] = test['EntryHeading'].map(directions)\n",
    "test['ExitHeading'] = test['ExitHeading'].map(directions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['diffHeading'] = train['EntryHeading']-train['ExitHeading']  \n",
    "test['diffHeading'] = test['EntryHeading']-test['ExitHeading'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### <span style='color:blue;background:yellow'>entering street == exit street?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"same_street_exact\"] = (train[\"EntryStreetName\"] ==  train[\"ExitStreetName\"]).astype(int)\n",
    "test[\"same_street_exact\"] = (test[\"EntryStreetName\"] ==  test[\"ExitStreetName\"]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue;background:yellow'>Make a new columns--> Intersection ID + City name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Intersection\"] = train[\"IntersectionId\"].astype(str) + train[\"City\"]\n",
    "test[\"Intersection\"] = test[\"IntersectionId\"].astype(str) + test[\"City\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(pd.concat([train[\"Intersection\"],test[\"Intersection\"]]).drop_duplicates().values)\n",
    "train[\"Intersection\"] = encoder.transform(train[\"Intersection\"])\n",
    "test[\"Intersection\"] = encoder.transform(test[\"Intersection\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue;background:yellow'> Add temperature (Â°F) of each city by month </span>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_av = {'Atlanta1': 43, 'Atlanta5': 69, 'Atlanta6': 76, 'Atlanta7': 79, 'Atlanta8': 78, 'Atlanta9': 73,\n",
    "              'Atlanta10': 62, 'Atlanta11': 53, 'Atlanta12': 45, 'Boston1': 30, 'Boston5': 59, 'Boston6': 68,\n",
    "              'Boston7': 74, 'Boston8': 73, 'Boston9': 66, 'Boston10': 55,'Boston11': 45, 'Boston12': 35,\n",
    "              'Chicago1': 27, 'Chicago5': 60, 'Chicago6': 70, 'Chicago7': 76, 'Chicago8': 76, 'Chicago9': 68,\n",
    "              'Chicago10': 56,  'Chicago11': 45, 'Chicago12': 32, 'Philadelphia1': 35, 'Philadelphia5': 66,\n",
    "              'Philadelphia6': 76, 'Philadelphia7': 81, 'Philadelphia8': 79, 'Philadelphia9': 72, 'Philadelphia10': 60,\n",
    "              'Philadelphia11': 49, 'Philadelphia12': 40}\n",
    "# Concatenating the city and month into one variable\n",
    "train['city_month'] = train[\"City\"] + train[\"Month\"].astype(str)\n",
    "test['city_month'] = test[\"City\"] + test[\"Month\"].astype(str)\n",
    "\n",
    "# Creating a new column by mapping the city_month variable to it's corresponding average monthly temperature\n",
    "train[\"average_temp\"] = train['city_month'].map(monthly_av)\n",
    "test[\"average_temp\"] = test['city_month'].map(monthly_av)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue;background:yellow'> Add climate data </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_rainfall = {'Atlanta1': 5.02, 'Atlanta5': 3.95, 'Atlanta6': 3.63, 'Atlanta7': 5.12, 'Atlanta8': 3.67, 'Atlanta9': 4.09,\n",
    "              'Atlanta10': 3.11, 'Atlanta11': 4.10, 'Atlanta12': 3.82, 'Boston1': 3.92, 'Boston5': 3.24, 'Boston6': 3.22,\n",
    "              'Boston7': 3.06, 'Boston8': 3.37, 'Boston9': 3.47, 'Boston10': 3.79,'Boston11': 3.98, 'Boston12': 3.73,\n",
    "              'Chicago1': 1.75, 'Chicago5': 3.38, 'Chicago6': 3.63, 'Chicago7': 3.51, 'Chicago8': 4.62, 'Chicago9': 3.27,\n",
    "              'Chicago10': 2.71,  'Chicago11': 3.01, 'Chicago12': 2.43, 'Philadelphia1': 3.52, 'Philadelphia5': 3.88,\n",
    "              'Philadelphia6': 3.29, 'Philadelphia7': 4.39, 'Philadelphia8': 3.82, 'Philadelphia9':3.88 , 'Philadelphia10': 2.75,\n",
    "              'Philadelphia11': 3.16, 'Philadelphia12': 3.31}\n",
    "# Creating a new column by mapping the city_month variable to it's corresponding average monthly rainfall\n",
    "train[\"average_rainfall\"] = train['city_month'].map(monthly_rainfall)\n",
    "test[\"average_rainfall\"] = test['city_month'].map(monthly_rainfall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_snowfall = {'Atlanta1': 0.6, 'Atlanta5': 0, 'Atlanta6': 0, 'Atlanta7': 0, 'Atlanta8': 0, 'Atlanta9': 0,\n",
    "              'Atlanta10': 0, 'Atlanta11': 0, 'Atlanta12': 0.2, 'Boston1': 12.9, 'Boston5': 0, 'Boston6': 0,\n",
    "              'Boston7': 0, 'Boston8': 0, 'Boston9': 0, 'Boston10': 0,'Boston11': 1.3, 'Boston12': 9.0,\n",
    "              'Chicago1': 11.5, 'Chicago5': 0, 'Chicago6': 0, 'Chicago7': 0, 'Chicago8': 0, 'Chicago9': 0,\n",
    "              'Chicago10': 0,  'Chicago11': 1.3, 'Chicago12': 8.7, 'Philadelphia1': 6.5, 'Philadelphia5': 0,\n",
    "              'Philadelphia6': 0, 'Philadelphia7': 0, 'Philadelphia8': 0, 'Philadelphia9':0 , 'Philadelphia10': 0,\n",
    "              'Philadelphia11': 0.3, 'Philadelphia12': 3.4}\n",
    "\n",
    "# Creating a new column by mapping the city_month variable to it's corresponding average monthly snowfall\n",
    "train[\"average_snowfall\"] = train['city_month'].map(monthly_snowfall)\n",
    "test[\"average_snowfall\"] = test['city_month'].map(monthly_snowfall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_daylight = {'Atlanta1': 10, 'Atlanta5': 14, 'Atlanta6': 14, 'Atlanta7': 14, 'Atlanta8': 13, 'Atlanta9': 12,\n",
    "              'Atlanta10': 11, 'Atlanta11': 10, 'Atlanta12': 10, 'Boston1': 9, 'Boston5': 15, 'Boston6': 15,\n",
    "              'Boston7': 15, 'Boston8': 14, 'Boston9': 12, 'Boston10': 11,'Boston11': 10, 'Boston12': 9,\n",
    "              'Chicago1': 10, 'Chicago5': 15, 'Chicago6': 15, 'Chicago7': 15, 'Chicago8': 14, 'Chicago9': 12,\n",
    "              'Chicago10': 11,  'Chicago11': 10, 'Chicago12': 9, 'Philadelphia1': 10, 'Philadelphia5': 14,\n",
    "              'Philadelphia6': 15, 'Philadelphia7': 15, 'Philadelphia8': 14, 'Philadelphia9':12 , 'Philadelphia10': 11,\n",
    "              'Philadelphia11': 10, 'Philadelphia12': 9}\n",
    "\n",
    "# Creating a new column by mapping the city_month variable to it's corresponding average monthly daylight\n",
    "train[\"average_daylight\"] = train['city_month'].map(monthly_daylight)\n",
    "test[\"average_daylight\"] = test['city_month'].map(monthly_daylight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_sunsine = {'Atlanta1': 5.3, 'Atlanta5': 9.3, 'Atlanta6': 9.5, 'Atlanta7': 8.8, 'Atlanta8': 8.3, 'Atlanta9': 7.6,\n",
    "              'Atlanta10': 7.7, 'Atlanta11': 6.2, 'Atlanta12': 5.3, 'Boston1': 5.3, 'Boston5': 8.6, 'Boston6': 9.6,\n",
    "              'Boston7': 9.7, 'Boston8': 8.9, 'Boston9': 7.9, 'Boston10': 6.7,'Boston11': 4.8, 'Boston12': 4.6,\n",
    "              'Chicago1': 4.4, 'Chicago5': 9.1, 'Chicago6': 10.4, 'Chicago7': 10.3, 'Chicago8': 9.1, 'Chicago9': 7.6,\n",
    "              'Chicago10': 6.2,  'Chicago11': 3.6, 'Chicago12': 3.4, 'Philadelphia1': 5.0, 'Philadelphia5': 7.9,\n",
    "              'Philadelphia6': 9.0, 'Philadelphia7': 8.9, 'Philadelphia8': 8.4, 'Philadelphia9':7.9 , 'Philadelphia10': 6.6,\n",
    "              'Philadelphia11': 5.2, 'Philadelphia12': 4.4}\n",
    "\n",
    "# Creating a new column by mapping the city_month variable to it's corresponding average monthly sunsine\n",
    "train[\"average_sunsine\"] = train['city_month'].map(monthly_sunsine)\n",
    "test[\"average_sunsine\"] = test['city_month'].map(monthly_sunsine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('city_month', axis=1, inplace=True)\n",
    "test.drop('city_month', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue;background:yellow'> New feature --> is_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['is_day'] = train['Hour'].apply(lambda x: 1 if 5 < x < 20 else 0)\n",
    "test['is_day'] = test['Hour'].apply(lambda x: 1 if 5 < x < 20 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue;background:yellow'>  Distance from center of city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_distance(df):\n",
    "    \n",
    "    df_center = pd.DataFrame({\"Atlanta\":[33.753746, -84.386330],\n",
    "                             \"Boston\":[42.361145, -71.057083],\n",
    "                             \"Chicago\":[41.881832, -87.623177],\n",
    "                             \"Philadelphia\":[39.952583, -75.165222]})\n",
    "    \n",
    "    df[\"CenterDistance\"] = df.apply(lambda row: math.sqrt((df_center[row.City][0] - row.Latitude) ** 2 +\n",
    "                                                          (df_center[row.City][1] - row.Longitude) ** 2) , axis=1)\n",
    "\n",
    "add_distance(train)\n",
    "add_distance(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <span style='color:blue;background:yellow'>  HotEncoding of cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train,pd.get_dummies(train[\"City\"],dummy_na=False, drop_first=False)],axis=1).drop([\"City\"],axis=1)\n",
    "test = pd.concat([test,pd.get_dummies(test[\"City\"],dummy_na=False, drop_first=False)],axis=1).drop([\"City\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale Log and lat columns\n",
    "scaler = StandardScaler()\n",
    "for col in ['Latitude','Longitude']:\n",
    "    scaler.fit(train[col].values.reshape(-1, 1))\n",
    "    train[col] = scaler.transform(train[col].values.reshape(-1, 1))\n",
    "    test[col] = scaler.transform(test[col].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_road_id = train['RowId']\n",
    "test_road_id = test['RowId']\n",
    "preds = train.iloc[:,12:27]\n",
    "train.drop(['RowId', 'Path','EntryStreetName','ExitStreetName'],axis=1, inplace=True)\n",
    "test.drop(['RowId', 'Path','EntryStreetName','ExitStreetName'],axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(16,12))\n",
    "sns.heatmap(train.corr(), color ='BGR4R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(preds.columns.tolist(), axis=1, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target1 = preds['TotalTimeStopped_p20']\n",
    "target2 = preds['TotalTimeStopped_p50']\n",
    "target3 = preds['TotalTimeStopped_p80']\n",
    "target4 = preds['DistanceToFirstStop_p20']\n",
    "target5 = preds['DistanceToFirstStop_p50']\n",
    "target6 = preds['DistanceToFirstStop_p80']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat = ['IntersectionId','Hour', 'Weekend','Month', 'same_street_exact', 'Intersection',\n",
    "       'Atlanta', 'Boston', 'Chicago', 'Philadelphia', 'EntryType', 'ExitType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds ={0:[],1:[],2:[],3:[],4:[],5:[]}\n",
    "all_target = [target1, target2, target3, target4, target5, target6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference: https://medium.com/analytics-vidhya/hyperparameters-optimization-for-lightgbm-catboost-and-xgboost-regressors-using-bayesian-6e7c495947a9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = lgb.Dataset(data=train, label=target3)\n",
    "\n",
    "# Objective Function\n",
    "def hyp_lgbm(num_leaves, feature_fraction, bagging_fraction, max_depth, min_split_gain, min_child_weight, lambda_l1, lambda_l2):\n",
    "      \n",
    "        params = {'application':'regression','num_iterations': 450,\n",
    "                  'learning_rate':0.02,\n",
    "                  'metric':'rmse'} # Default parameters\n",
    "        params[\"num_leaves\"] = int(round(num_leaves))\n",
    "        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
    "        params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n",
    "        params['max_depth'] = int(round(max_depth))\n",
    "        params['min_split_gain'] = min_split_gain\n",
    "        params['min_child_weight'] = min_child_weight\n",
    "        params['lambda_l1'] = lambda_l1\n",
    "        params['lambda_l2'] = lambda_l2\n",
    "        \n",
    "        cv_results = lgb.cv(params, dtrain, nfold=5, seed=17,categorical_feature=cat_feat, stratified=False,\n",
    "                            verbose_eval =None)\n",
    "#         print(cv_results)\n",
    "        return -np.min(cv_results['rmse-mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain space-- Range of hyperparameters\n",
    "pds = {'num_leaves': (120, 230),\n",
    "          'feature_fraction': (0.3, 0.9),\n",
    "          'bagging_fraction': (0.8, 1),\n",
    "           'lambda_l1': (0,3),\n",
    "           'lambda_l2': (0,5),\n",
    "          'max_depth': (8, 19),\n",
    "          'min_split_gain': (0.001, 0.1),\n",
    "          'min_child_weight': (1, 20)\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surrogate model\n",
    "optimizer = BayesianOptimization(hyp_lgbm,pds,random_state=7)\n",
    "                                  \n",
    "# Optimize\n",
    "optimizer.maximize(init_points=5, n_iter=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = optimizer.max['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'num_leaves': int(round(p['num_leaves'])),\n",
    "         'feature_fraction': p['feature_fraction'],\n",
    "         'bagging_fraction': p['bagging_fraction'],\n",
    "         'max_depth': int(round(p['max_depth'])),\n",
    "         'lambda_l1': p['lambda_l1'],\n",
    "         'lambda_l2': p['lambda_l2'],\n",
    "         'min_split_gain': p['min_split_gain'],\n",
    "         'min_child_weight': p['min_child_weight'],\n",
    "         'learning_rate':0.05,\n",
    "         'objective': 'regression',\n",
    "         'boosting_type': 'gbdt',\n",
    "         'verbose': 1,\n",
    "         'metric': 'rmse',\n",
    "         'seed': 7,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nfold = 5\n",
    "kf = KFold(n_splits=nfold, random_state=227, shuffle=True)\n",
    "for i in range(len(all_preds)):\n",
    "    print('Training and predicting for target {}'.format(i+1))\n",
    "    oof = np.zeros(len(train))\n",
    "    all_preds[i] = np.zeros(len(test))\n",
    "    n =1\n",
    "    for train_index, valid_index in kf.split(all_target[i]):\n",
    "        print(\"fold {}\".format(n))\n",
    "        xg_train = lgb.Dataset(train.iloc[train_index],\n",
    "                               label=all_target[i][train_index]\n",
    "                               )\n",
    "        xg_valid = lgb.Dataset(train.iloc[valid_index],\n",
    "                               label=all_target[i][valid_index]\n",
    "                               )   \n",
    "\n",
    "        clf = lgb.train(param, xg_train, 15000, valid_sets=[xg_valid],categorical_feature=cat_feat\n",
    "                        , verbose_eval=200, early_stopping_rounds=500)\n",
    "        oof[valid_index] = clf.predict(train.iloc[valid_index], num_iteration=clf.best_iteration) \n",
    "\n",
    "        all_preds[i] += clf.predict(test, num_iteration=clf.best_iteration) / nfold\n",
    "        n = n + 1\n",
    "\n",
    "    print(\"\\n\\nCV RMSE: {:<0.4f}\".format(np.sqrt(mean_squared_error(all_target[i], oof))))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.DataFrame(all_preds).stack()\n",
    "data2 = pd.DataFrame(data2)\n",
    "submission['Target'] = data2[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><span style='color:blue;background:yellow;font-size:30px'>**Please upvote this notebook if you like my work. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References:**\n",
    "1. https://www.kaggle.com/whatust/fork-of-kernel56e53f4445\n",
    "2. https://www.kaggle.com/brokenfulcrum/geotab-baseline\n",
    "3. https://www.kaggle.com/danofer/baseline-feature-engineering-geotab-69-5-lb\n",
    "4.  https://www.kaggle.com/bgmello/how-one-percentile-affect-the-others"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
